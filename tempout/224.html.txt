date
wednesday
nov
gmt
server
ncsa
mime
version
content
type
text
html
last
modified
thursday
nov
gmt
content
length
cashmere
home
page
coherence
algorithms
for
shared
memory
architectures
the
cashmere
project
overview
people
papers
overview
cashmere
stands
for
coherence
algorithms
for
shared
memory
architectures
and
is
an
ongoing
effort
to
provide
efficient
scalable
shared
memory
with
minimal
hardware
support
it
is
well
accepted
today
that
commercial
workstations
offer
the
best
price
performance
ratio
and
that
shared
memory
provides
the
most
desirable
programming
paradigm
for
parallel
computing
unfortunately
shared
memory
emulations
on
networks
of
workstations
provide
acceptable
performance
for
only
a
limited
class
of
applications
cashmere
attempts
to
bridge
the
performance
gap
between
shared
memory
emulations
on
networks
of
workstations
and
tightly
coupled
cache
coherent
multiprocessors
while
using
minimal
hardware
support
in
the
context
of
cashmere
we
have
discovered
that
ncc
numa
non
cache
coherent
non
uniform
memory
access
machines
can
greatly
improve
the
performance
of
dsm
systems
and
approach
that
of
fully
hardware
coherent
multiprocessors
the
basic
property
of
ncc
numa
systems
is
the
ability
to
access
remote
memory
directly
such
a
capability
is
offered
by
a
variety
of
network
interfaces
including
dec
s
memory
channel
hp
s
hamlyn
and
the
princeton
shrimp
given
current
technology
the
additional
hardware
cost
of
ncc
numa
systems
over
pure
message
passing
systems
is
minimal
based
on
this
fact
and
our
performance
results
we
believe
that
ncc
numa
machines
lie
near
the
knee
of
the
price
performance
curve
the
department
of
computer
science
at
the
university
of
rochester
is
building
a
processor
cashmere
prototype
significant
part
of
the
funding
comes
in
the
form
of
an
equipment
grant
from
digital
equipment
corporation
the
prototype
consists
of
eight
processor
dec
multiprocessors
on
a
memory
channel
network
the
memory
channel
plugs
into
any
pci
bus
it
provides
a
memory
mapped
network
interface
with
which
processors
can
read
and
write
remote
locations
without
kernel
intervention
or
inter
processor
interrupts
end
to
end
bandwidth
is
currently
about
mb
sec
remote
write
latency
is
about
us
the
next
hardware
generation
is
expected
to
increase
bandwidth
by
approximately
one
order
of
magnitude
and
cut
latency
by
half
cashmere
augments
the
functionality
of
the
memory
channel
by
providing
cache
coherence
in
software
implementation
of
cashmere
slides
from
the
workshop
on
scalable
shared
memory
multiprocessors
boston
ma
october
cashmere
people
the
people
behind
cashmere
are
michael
l
scott
wei
li
sandhya
dwarkadas
leonidas
kontothanassis
galen
hunt
maged
michael
robert
stets
nikolaos
hardavellas
sotirios
ioannidis
wagner
meira
alexandros
poulos
michal
cierniak
srinivasan
parthasarathy
and
mohammed
zaki
cashmere
papers
g
c
hunt
and
m
l
scott
using
peer
support
to
reduce
fault
tolerant
overhead
in
distributed
shared
memories
tr
computer
science
department
university
of
rochester
june
l
i
kontothanassis
and
m
l
scott
efficient
shared
memory
with
minimal
hardware
support
in
computer
architecture
news
september
l
i
kontothanassis
and
m
l
scott
using
memory
mapped
network
interfaces
to
improve
the
performance
of
distributed
shared
memory
in
proc
nd
hpca
san
jose
ca
february
l
i
kontothanassis
m
l
scott
and
r
bianchini
lazy
release
consistency
for
hardware
coherent
multiprocessors
in
proc
supercomputing
san
diego
ca
december
l
i
kontothanassis
and
m
l
scott
software
cache
coherence
for
current
and
future
architectures
in
special
jpdc
issue
on
scalable
shared
memory
november
v29
n2
pp
l
i
kontothanassis
and
m
l
scott
software
cache
coherence
for
large
scale
multiprocessors
in
proc
st
hpca
raleigh
nc
january
m
marchetti
l
i
kontothanassis
r
bianchini
and
m
l
scott
using
simple
page
placement
policies
to
reduce
the
cost
of
cache
fills
in
coherent
shared
memory
systems
in
proc
ipps
santa
barbara
ca
april
m
cierniak
and
wei
li
unifying
data
and
control
transformations
for
distributed
shared
memory
machines
in
proc
sigplan
pldi
la
jolla
ca
june
also
available
as
tr
for
comments
and
or
requests
send
mail
to
kthanasi@crl.dec
com
or
scott@cs.rochester
edu
urcs
home
page
